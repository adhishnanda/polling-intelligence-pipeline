# Airflow-Orchestrated Polling Intelligence Pipeline
## Production-Style Batch ETL System (Apache Airflow + Python)

This project demonstrates a **Data Engineering pipeline orchestrated using Apache Airflow**.

The primary objective of this project is to showcase:

- Airflow DAG design
- Task orchestration and dependency management
- Modular ETL architecture
- Reproducible batch processing
- Data layer separation (Raw â†’ Curated â†’ Marts)
- Downstream artifact generation

The pipeline processes U.S. presidential polling data (FiveThirtyEight export snapshot) and produces structured analytical outputs and baseline prediction artifacts.

---

## ğŸš€ Core Focus: Apache Airflow

This project is intentionally built around **Airflow orchestration**.

All transformations and artifact generation are executed through Airflow DAGs.

Two DAGs are implemented:

1. **polling_intelligence_etl**
   - Ingestion
   - Cleaning & schema normalization
   - Analytics mart generation
   - ML-ready feature table creation

2. **polling_baseline_prediction**
   - Consumes cleaned dataset
   - Produces baseline aggregated prediction summary
   - Generates visualization artifact
   - Outputs prediction report

The DAGs were successfully executed and triggered via the Airflow UI.

---

## ğŸ“¸ Airflow Execution Proof

The pipeline was executed end-to-end using the Airflow UI.

### Airflow DAG List

Shows both ETL and prediction pipelines deployed in Airflow:

![Airflow DAG List](assets/screenshots/01_airflow_dag_list.png)

---

### ETL Pipeline DAG (Graph View)

This DAG orchestrates ingestion, cleaning, mart generation, and feature engineering:

![ETL DAG Graph](assets/screenshots/02_etl_dag_graph_01.png)
![ETL DAG Graph Expanded](assets/screenshots/02_etl_dag_graph_02.png)

---

### ETL Pipeline Successful Execution

All ETL tasks completed successfully:

![ETL DAG Success](assets/screenshots/03_etl_success.png)

---

### Baseline Prediction DAG

This downstream batch job consumes engineered features and produces prediction artifacts:

![Prediction DAG](assets/screenshots/04_prediction_graph.png)

---

### Prediction DAG Successful Execution

![Prediction DAG Success](assets/screenshots/05_prediction_success.png)

---

### Output Artifact Generated by Pipeline

Example visualization generated automatically by Airflow:

![Prediction Output](assets/screenshots/06_prediction_output.png)

---
---

## ğŸ§± System Architecture

### High-Level Architecture

![Architecture](assets/diagrams/architecture.svg)

---

### DAG Dependency Structure (ETL DAG)

![ETL DAG](assets/diagrams/etl_dag.svg)

---

### Data Lineage

![Data Lineage](assets/diagrams/data_lineage.svg)

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ polling_etl_dag.py
â”‚   â””â”€â”€ election_prediction_dag.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ analytics_marts.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ prediction.py
â”‚   â””â”€â”€ paths.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ marts/
â”‚
â”œâ”€â”€ reports/
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ streamlit_app.py
â”‚
â””â”€â”€ assets/
```

---

## ğŸ”„ Pipeline Flow (Detailed)

### 1. Ingestion
- Reads raw polling CSV snapshot
- Validates schema presence
- Passes DataFrame to transformation layer

### 2. Cleaning & Standardization
- Date parsing
- Numeric coercion
- Null handling
- Column selection
- String normalization

Output:
```
data/processed/polls_cleaned.csv
```

### 3. Analytics Marts
- State-level candidate vote share
- Key candidate comparison
- Sample size variance
- Polling trends time-series
- Pollster transparency aggregation

Outputs saved under:
```
data/marts/
```

### 4. Feature Engineering (ML-Ready Table)
Aggregated per candidate/state:
- Mean vote %
- Variance
- Poll counts
- Mean sample size
- Transparency score
- Temporal range

Output:
```
data/marts/mart_ml_features_candidate_level.csv
```

### 5. Baseline Scoring DAG
- Aggregates mean polling %
- Produces ranked candidate summary
- Generates bar plot artifact
- Writes winner text output

Outputs:
```
reports/prediction_summary.csv
assets/candidates_probability_visualization.png
reports/winner.txt
```

---

## ğŸ›  Engineering Decisions

- Separation of concerns via modular `src/`
- No hardcoded system paths
- TaskFlow API for Airflow clarity
- Clear dependency ordering
- Layered storage design
- Idempotent batch design

---

## ğŸ§  Why This Matters for Data Engineering Roles

This project demonstrates:

- Real DAG construction
- Task grouping and dependency control
- Modular ETL architecture
- Data layer abstraction
- Artifact generation for downstream ML systems
- Production-style folder structuring
- Reproducible batch processing

Airflow orchestration is the central engineering skill highlighted here.

---

## âš™ï¸ Running the Project

### 1. Environment Setup

```bash
python -m venv .venv
.\.venv\Scripts\Activate.ps1   # Windows
pip install -r requirements.txt
```

### 2. Quick Local Execution (Without Airflow)

```bash
python run_local_once.py
```

### 3. Running via Airflow (Optional)

### Running via Apache Airflow (Full Pipeline Execution)

This project was developed and tested using Airflow inside WSL (Linux environment recommended).

Step 1: Clone repository

git clone https://github.com/adhishnanda/polling-intelligence-pipeline.git

cd polling-intelligence-pipeline

---

Step 2: Create Python environment

python3.10 -m venv airflow_venv

source airflow_venv/bin/activate

pip install -r requirements.txt

---

Step 3: Set environment variables

export PIPELINE_ROOT=$(pwd)

export AIRFLOW_HOME=$(pwd)/airflow

export PYTHONPATH=$(pwd)

---

Step 4: Initialize Airflow

airflow db init

---

Step 5: Start Airflow

airflow standalone

---

Step 6: Open UI

http://localhost:8080

---

Step 7: Trigger DAGs

Run in order:

polling_intelligence_etl

then

polling_baseline_prediction

---

Step 8: Verify outputs generated in:

data/processed/

data/marts/

reports/

assets/

---

## ğŸ“ˆ Interactive Dashboard (Streamlit)

A Streamlit dashboard was built as a presentation layer on top of the Airflow pipeline outputs.

The dashboard reads processed data, analytics marts, and prediction artifacts generated by the pipeline and provides interactive visualizations.

This demonstrates how Airflow pipelines can power downstream analytics applications.

### Dashboard Screenshots

#### Polling Trends

![Polling Trends](assets/screenshots/Polling_Trends.png)

---

#### Candidate Transparency Analysis

![Transparency Score](assets/screenshots/Transparency_Score.png)

---

#### Top Candidates Overview

![Top Candidates](assets/screenshots/Top_Candidates.png)

---

#### Full Dashboard View

![Streamlit Dashboard](assets/screenshots/Streamlit_Dashboard.png)

---

### Running Dashboard

```bash
streamlit run dashboard/streamlit_app.py
```

---

## ğŸ”® Future Improvements (Designed but Not Implemented)

- Automated ingestion via API
- Data validation framework (Great Expectations)
- PostgreSQL data warehouse layer
- Dockerized deployment
- Scheduled retraining workflow
- CI/CD integration

---

## ğŸ“Œ Summary

This project is an Airflow-centric batch ETL system designed to demonstrate:

âœ” DAG orchestration  
âœ” Modular pipeline design  
âœ” Data layer separation  
âœ” ML feature preparation  
âœ” Artifact generation  
âœ” Production-style structuring  

The core engineering focus is Apache Airflow orchestration and pipeline architecture.
